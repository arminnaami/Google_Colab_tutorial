{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Google_Colab_tutorial.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hjKE6QCD9ez",
        "colab_type": "text"
      },
      "source": [
        "## Intro.\n",
        "\n",
        "It is example codes and script for explaining about Google Colab. \n",
        "\n",
        "My ways are not the optimal way to use Colab, but I think these are helpful enough to increase experiment speed.\n",
        "\n",
        "\n",
        "## What is Google Colab.\n",
        "https://www.youtube.com/watch?v=inN8seMm7UI\n",
        "\n",
        "Google Colab(GC) is **free**  machine learning tool for studying and researching.\n",
        "\n",
        "It means that you can run your codes in GC, which contains a powerful GPU machine.\n",
        "\n",
        "and its only limitation is the maximum running time, which is 12 hours.\n",
        "\n",
        "and it is connected to your Google drive so you can access GC GPU anytime.\n",
        "\n",
        "So there is no reason not to use GC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3udZ7cCG2a6",
        "colab_type": "text"
      },
      "source": [
        "# How to Use GC\n",
        "\n",
        "## Connect with your Google drive\n",
        "\n",
        "If you want to use GC, Google drive is needed for saving codes, datasets, training log, and so on.\n",
        "\n",
        "so the first step is connecting to Google Driver.\n",
        "\n",
        "\n",
        "Look below code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odw4J82VExjd",
        "colab_type": "code",
        "outputId": "ba4df8cf-cc8e-47ac-bc45-dd9c79cc79c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cleyIr7JITja",
        "colab_type": "text"
      },
      "source": [
        "this code connect your google drive to GC\n",
        "\n",
        "it is run by ctrl + Enter.\n",
        "\n",
        "if you run this code, return some URL and you can fine authorization code in there.\n",
        "\n",
        "After printed \n",
        "\n",
        "\"Mounted at /content/gdrive\"\n",
        "\n",
        "you can access you google driver in GC like below image and your home path is set to ''/content'' \n",
        "\n",
        "![](https://drive.google.com/uc?id=1bmWrRZYzyb1b4WkaXt9a9bgM9cTEoLyk)\n",
        "\n",
        "\n",
        "It is Korean, but the button's location is the same I think\n",
        "\n",
        "Next, I'll make some folder in my Google drive to upload new codes by the below code.\n",
        "\n",
        "As you can see if you add '!' in front of code line, it runs in the terminal\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa57dSchNeJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir gdrive/My\\ Drive/testing_folder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XF8hYazO-5R",
        "colab_type": "text"
      },
      "source": [
        "![](https://drive.google.com/open?id=1-qcpHtM6Tkwhd2fYXUcErorPqBfUYwnX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWpl_eUDPPVe",
        "colab_type": "text"
      },
      "source": [
        "![](https://drive.google.com/uc?id=1PvNolorXaIgs9ls9ldvCypa-hdtfj5aX)\n",
        "\n",
        "\n",
        "As you can see, a new folder is made in Google drive.\n",
        "\n",
        "it is possible to make a new folder in Google driver surely, but I want to show that it is not so different from our computer.\n",
        "\n",
        "\n",
        "## Upload codes in Google Colab\n",
        "\n",
        "The next step is uploading a bunch of codes. I'll explain how to code in GC, but it is not so comfortable.\n",
        "\n",
        "So if you have to modify many things, work on your computer is better.\n",
        "\n",
        "if you upload codes in the folder, you can see in GC also.\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?id=1w1_xa1apDJhe2xcoXFuZBHJEA-16bBMe)\n",
        "\n",
        "\n",
        "## GPU setting\n",
        "You surely want to run your codes in GPU. So you have to change the runtime type.\n",
        "\n",
        "![](https://drive.google.com/uc?id=17X0FqZzLCjEeJhn_13WPZFnb6McPcMzH)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SfVIbgHVks4",
        "colab_type": "code",
        "outputId": "5155e958-90a2-4366-b70f-c51892c567a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Apr 24 17:13:22 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.56       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8    16W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mi2xNhzFVwRp",
        "colab_type": "text"
      },
      "source": [
        "it's done, and Tesla T4 is yours!\n",
        "\n",
        "## Start Tensorboard\n",
        "I think analyzing the learning plot is very important. so I'll explain about how to run Tensorboard in GC\n",
        "\n",
        "I set training path to\" test\"\n",
        "\n",
        "So Tensorboard is run by the below codes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUb-PUKwXIMv",
        "colab_type": "code",
        "outputId": "df3185d7-8536-42bc-deb6-b9d3f8279a85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-25 01:47:07--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 34.199.255.1, 34.206.36.121, 35.172.177.65, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|34.199.255.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14991793 (14M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab  14%[=>                  ]   2.02M  10.1MB/s               \rngrok-stable-linux- 100%[===================>]  14.30M  41.7MB/s    in 0.3s    \n",
            "\n",
            "2019-04-25 01:47:07 (41.7 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [14991793/14991793]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjnnUfeDauZK",
        "colab_type": "code",
        "outputId": "21209deb-3a84-4d95-c246-c6bda344fae7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "LOG_DIR = 'test'\n",
        "\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir={} --host=0.0.0.0 --port=6006 &'\n",
        "    .format(LOG_DIR))\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://769ca309.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTcypKPuLgfJ",
        "colab_type": "text"
      },
      "source": [
        "when all process is done, you can see some link in last line and the page show Tensorboard\n",
        "\n",
        "you can check running of Tensorboard by the process manager"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4iKnACILxSx",
        "colab_type": "code",
        "outputId": "54a50285-1834-4918-8a72-4e47d617c609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "!ps -A"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    PID TTY          TIME CMD\n",
            "      1 ?        00:00:00 run.sh\n",
            "     10 ?        00:00:00 node\n",
            "     25 ?        00:00:00 node\n",
            "     35 ?        00:00:01 jupyter-noteboo\n",
            "    122 ?        00:00:00 tail\n",
            "    130 ?        00:00:01 python3\n",
            "    166 ?        00:00:00 drive\n",
            "    248 ?        00:00:00 drive\n",
            "    296 ?        00:00:00 tail\n",
            "    297 ?        00:00:00 grep\n",
            "    322 ?        00:00:01 tensorboard\n",
            "    324 ?        00:00:00 ngrok\n",
            "    516 ?        00:00:00 ps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zuJ1OqYXxuv",
        "colab_type": "text"
      },
      "source": [
        "As you can see, Tensorboard is running backend.\n",
        "\n",
        "## Training the code\n",
        "\n",
        "you are ready for training the codes.\n",
        "\n",
        "if you run the \"train.py\" you can see the training process in terminal and Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9Fq_uduYMCi",
        "colab_type": "code",
        "cellView": "code",
        "outputId": "7a689def-f07f-40ba-aa07-3fb9842bb5d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1381
        }
      },
      "source": [
        "!python /content/gdrive/My\\ Drive/testing_folder/tensorflow_classifier/train.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "2019-04-25 01:47:41.121644: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-04-25 01:47:41.121936: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x189b5a0 executing computations on platform Host. Devices:\n",
            "2019-04-25 01:47:41.121967: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-04-25 01:47:41.330118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-04-25 01:47:41.330606: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x189b2e0 executing computations on platform CUDA. Devices:\n",
            "2019-04-25 01:47:41.330634: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-04-25 01:47:41.330989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 14.73GiB freeMemory: 14.60GiB\n",
            "2019-04-25 01:47:41.331012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-04-25 01:47:42.634111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-04-25 01:47:42.634158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-04-25 01:47:42.634170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-04-25 01:47:42.634488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14115 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "network built\n",
            "2019-04-25 01:47:43.153617: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
            "Epoch 000 Step 000000 - train_Accuracy : 0.12%  val_Accuracy : 9.96%\n",
            "Epoch 001 Step 000078 - train_Accuracy : 31.35%  val_Accuracy : 44.42%\n",
            "global step 000100: loss = 2.0330 (0.052 sec/step)\n",
            "Epoch 002 Step 000156 - train_Accuracy : 45.16%  val_Accuracy : 50.31%\n",
            "global step 000200: loss = 1.6412 (0.017 sec/step)\n",
            "Epoch 003 Step 000234 - train_Accuracy : 50.75%  val_Accuracy : 54.11%\n",
            "global step 000300: loss = 1.4761 (0.017 sec/step)\n",
            "Epoch 004 Step 000312 - train_Accuracy : 55.21%  val_Accuracy : 55.11%\n",
            "Epoch 005 Step 000390 - train_Accuracy : 58.77%  val_Accuracy : 59.12%\n",
            "global step 000400: loss = 1.3556 (0.017 sec/step)\n",
            "Epoch 006 Step 000468 - train_Accuracy : 61.66%  val_Accuracy : 61.16%\n",
            "global step 000500: loss = 1.2527 (0.017 sec/step)\n",
            "Epoch 007 Step 000546 - train_Accuracy : 64.89%  val_Accuracy : 62.39%\n",
            "global step 000600: loss = 1.1504 (0.017 sec/step)\n",
            "Epoch 008 Step 000624 - train_Accuracy : 67.54%  val_Accuracy : 64.25%\n",
            "global step 000700: loss = 1.0740 (0.017 sec/step)\n",
            "Epoch 009 Step 000702 - train_Accuracy : 69.42%  val_Accuracy : 62.96%\n",
            "Epoch 010 Step 000780 - train_Accuracy : 71.39%  val_Accuracy : 65.39%\n",
            "global step 000800: loss = 0.9824 (0.017 sec/step)\n",
            "Epoch 011 Step 000858 - train_Accuracy : 77.44%  val_Accuracy : 67.74%\n",
            "global step 000900: loss = 0.8328 (0.017 sec/step)\n",
            "Epoch 012 Step 000936 - train_Accuracy : 78.51%  val_Accuracy : 67.85%\n",
            "global step 001000: loss = 0.8058 (0.017 sec/step)\n",
            "Epoch 013 Step 001014 - train_Accuracy : 79.39%  val_Accuracy : 68.21%\n",
            "Epoch 014 Step 001092 - train_Accuracy : 80.40%  val_Accuracy : 67.84%\n",
            "global step 001100: loss = 0.7853 (0.017 sec/step)\n",
            "Epoch 015 Step 001170 - train_Accuracy : 80.63%  val_Accuracy : 67.80%\n",
            "global step 001200: loss = 0.7548 (0.017 sec/step)\n",
            "Epoch 016 Step 001248 - train_Accuracy : 82.02%  val_Accuracy : 68.50%\n",
            "global step 001300: loss = 0.7401 (0.017 sec/step)\n",
            "Epoch 017 Step 001326 - train_Accuracy : 81.40%  val_Accuracy : 68.46%\n",
            "global step 001400: loss = 0.7344 (0.017 sec/step)\n",
            "Epoch 018 Step 001404 - train_Accuracy : 81.92%  val_Accuracy : 68.70%\n",
            "Epoch 019 Step 001482 - train_Accuracy : 81.33%  val_Accuracy : 68.53%\n",
            "global step 001500: loss = 0.7376 (0.017 sec/step)\n",
            "Epoch 020 Step 001560 - train_Accuracy : 81.55%  val_Accuracy : 68.54%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JS82dKZffMeK",
        "colab_type": "text"
      },
      "source": [
        "![](https://drive.google.com/uc?id=1WCkdnD_aRTHrNU1UxrR26EEWPDUI5w8p)\n",
        "\n",
        "training result is not so good so you have to modify hyper-parameters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e6W7G9Zc_8r",
        "colab_type": "text"
      },
      "source": [
        "## Modifying Code\n",
        "If you want to modify just some of the hyper-parameters, re-uploading codes are so uncomfortable.\n",
        "\n",
        "so we need some text editor that can modify the codes in Google drive.\n",
        "\n",
        "![](https://drive.google.com/uc?id=1T3BvM1kPUBiOFePmebcS65oMCkW8cdMC)\n",
        "\n",
        "Text Editor for Drive is suitable for this, I think.\n",
        "\n",
        "it can access your Google Drive and edit the codes.\n",
        "\n",
        "So I modify some hyper-parameters and run again.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIu9zBxPenmH",
        "colab_type": "code",
        "outputId": "58ae9b34-2a3a-4f37-b3d3-ee75afb5c694",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1381
        }
      },
      "source": [
        "!python /content/gdrive/My\\ Drive/testing_folder/tensorflow_classifier/train.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "2019-04-24 17:53:03.468149: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-04-24 17:53:03.468353: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2be55a0 executing computations on platform Host. Devices:\n",
            "2019-04-24 17:53:03.468382: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-04-24 17:53:03.619201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-04-24 17:53:03.619705: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2be52e0 executing computations on platform CUDA. Devices:\n",
            "2019-04-24 17:53:03.619733: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-04-24 17:53:03.620075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 14.73GiB freeMemory: 14.60GiB\n",
            "2019-04-24 17:53:03.620099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-04-24 17:53:04.063532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-04-24 17:53:04.063598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-04-24 17:53:04.063624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-04-24 17:53:04.063902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14115 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "network built\n",
            "2019-04-24 17:53:04.480057: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
            "Epoch 000 Step 000000 - train_Accuracy : 0.12%  val_Accuracy : 10.59%\n",
            "Epoch 001 Step 000078 - train_Accuracy : 30.92%  val_Accuracy : 43.69%\n",
            "global step 000100: loss = 2.0510 (0.038 sec/step)\n",
            "Epoch 002 Step 000156 - train_Accuracy : 44.62%  val_Accuracy : 48.42%\n",
            "global step 000200: loss = 1.6533 (0.016 sec/step)\n",
            "Epoch 003 Step 000234 - train_Accuracy : 49.97%  val_Accuracy : 52.79%\n",
            "global step 000300: loss = 1.4867 (0.017 sec/step)\n",
            "Epoch 004 Step 000312 - train_Accuracy : 54.30%  val_Accuracy : 56.65%\n",
            "Epoch 005 Step 000390 - train_Accuracy : 58.03%  val_Accuracy : 59.30%\n",
            "global step 000400: loss = 1.3695 (0.016 sec/step)\n",
            "Epoch 006 Step 000468 - train_Accuracy : 61.55%  val_Accuracy : 61.59%\n",
            "global step 000500: loss = 1.2589 (0.016 sec/step)\n",
            "Epoch 007 Step 000546 - train_Accuracy : 63.78%  val_Accuracy : 61.93%\n",
            "global step 000600: loss = 1.1647 (0.016 sec/step)\n",
            "Epoch 008 Step 000624 - train_Accuracy : 67.26%  val_Accuracy : 62.78%\n",
            "global step 000700: loss = 1.0853 (0.017 sec/step)\n",
            "Epoch 009 Step 000702 - train_Accuracy : 68.99%  val_Accuracy : 63.04%\n",
            "Epoch 010 Step 000780 - train_Accuracy : 71.47%  val_Accuracy : 65.08%\n",
            "global step 000800: loss = 0.9883 (0.016 sec/step)\n",
            "Epoch 011 Step 000858 - train_Accuracy : 76.86%  val_Accuracy : 67.23%\n",
            "global step 000900: loss = 0.8524 (0.016 sec/step)\n",
            "Epoch 012 Step 000936 - train_Accuracy : 78.43%  val_Accuracy : 67.74%\n",
            "global step 001000: loss = 0.8144 (0.017 sec/step)\n",
            "Epoch 013 Step 001014 - train_Accuracy : 79.02%  val_Accuracy : 67.46%\n",
            "Epoch 014 Step 001092 - train_Accuracy : 79.50%  val_Accuracy : 67.87%\n",
            "global step 001100: loss = 0.7962 (0.017 sec/step)\n",
            "Epoch 015 Step 001170 - train_Accuracy : 79.94%  val_Accuracy : 68.19%\n",
            "global step 001200: loss = 0.7767 (0.017 sec/step)\n",
            "Epoch 016 Step 001248 - train_Accuracy : 81.10%  val_Accuracy : 68.21%\n",
            "global step 001300: loss = 0.7489 (0.016 sec/step)\n",
            "Epoch 017 Step 001326 - train_Accuracy : 80.85%  val_Accuracy : 68.18%\n",
            "global step 001400: loss = 0.7606 (0.017 sec/step)\n",
            "Epoch 018 Step 001404 - train_Accuracy : 81.10%  val_Accuracy : 68.32%\n",
            "Epoch 019 Step 001482 - train_Accuracy : 81.22%  val_Accuracy : 68.24%\n",
            "global step 001500: loss = 0.7535 (0.017 sec/step)\n",
            "Epoch 020 Step 001560 - train_Accuracy : 81.34%  val_Accuracy : 68.32%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQGkNcjoeyom",
        "colab_type": "text"
      },
      "source": [
        "later one which called test0 is better than the former one\n",
        "\n",
        "![](https://drive.google.com/uc?id=1wfpIlwhfDrVMSLXG30PzXB-l38tF0RZB)\n",
        "\n",
        "and if you want to change logdir of Tensorboard, you have to kill running Tensorboard and rerun the Tensorboard\n",
        "\n",
        "all progress is explained in below codes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3woZGfsvMkZZ",
        "colab_type": "code",
        "outputId": "b5e3f87b-ca81-475b-a96a-ce5fdd883fd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "!ps -A"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    PID TTY          TIME CMD\n",
            "      1 ?        00:00:00 run.sh\n",
            "     10 ?        00:00:00 node\n",
            "     25 ?        00:00:00 node\n",
            "     35 ?        00:00:01 jupyter-noteboo\n",
            "    122 ?        00:00:00 tail\n",
            "    130 ?        00:00:01 python3\n",
            "    166 ?        00:00:00 drive\n",
            "    248 ?        00:00:01 drive\n",
            "    296 ?        00:00:00 tail\n",
            "    297 ?        00:00:00 grep\n",
            "    322 ?        00:00:02 tensorboard\n",
            "    324 ?        00:00:01 ngrok\n",
            "    592 ?        00:00:00 ps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L__XJIRLMoP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kill -9 322"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eDene_bMsDH",
        "colab_type": "code",
        "outputId": "17147cc9-aa66-4e14-8eaa-444d6004b412",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "LOG_DIR = 'test/test1'\n",
        "\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir={} --host=0.0.0.0 --port=6006 &'\n",
        "    .format(LOG_DIR))\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://769ca309.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toec57lJNCMH",
        "colab_type": "text"
      },
      "source": [
        "That's all and enjoy you free GPU :)"
      ]
    }
  ]
}